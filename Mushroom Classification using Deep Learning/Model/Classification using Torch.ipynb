{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f09a8bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bec1e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:\n",
    "    dev = \"cpu\"  \n",
    "    \n",
    "device = torch.device(dev)  \n",
    "a = torch.zeros(4,3)    \n",
    "a = a.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2b42b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc445a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Agaricus',\n",
       " 'Amanita',\n",
       " 'Boletus',\n",
       " 'Cortinarius',\n",
       " 'Entoloma',\n",
       " 'Hygrocybe',\n",
       " 'Lactarius',\n",
       " 'Russula',\n",
       " 'Suillus']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('D://ML DL AI DSBDA//Mushroom Classification using Deep Learning//archive//Mushrooms//')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09716525",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_transforms = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7df7b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_path = 'D://ML DL AI DSBDA//Mushroom Classification using Deep Learning//archive//Mushrooms//'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e5e775c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.ImageFolder(root = train_dataset_path, transform = training_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd4e22ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size = 32, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7b114b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_std(loader):\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    total_images_count = 0\n",
    "    for images, _ in loader:\n",
    "        image_count_in_a_batch = images.size(0)\n",
    "        images = images.view(image_count_in_a_batch, images.size(1), -1)\n",
    "        mean += images.mean(2).sum(0)\n",
    "        std += images.std(2).sum(0)\n",
    "        total_images_count += image_count_in_a_batch\n",
    "        \n",
    "    mean = mean/total_images_count\n",
    "    std = std/total_images_count\n",
    "    \n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "274dd840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.3913, 0.3696, 0.2827]), tensor([0.2292, 0.2094, 0.2030]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean, std = get_mean_std(train_loader)\n",
    "mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6e7db87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the desired split ratio (e.g., 80% for training, 20% for testing)\n",
    "train_ratio = 0.8\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "random_seed = 42\n",
    "\n",
    "# Define the data transformations\n",
    "transform = transforms.Compose([\n",
    "    # transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff9e8e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b39fce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the entire dataset using ImageFolder\n",
    "full_dataset = ImageFolder(root = train_dataset_path, transform = transform)\n",
    "\n",
    "# Set the random seed\n",
    "random.seed(random_seed)\n",
    "\n",
    "# Determine the size of the training set based on the split ratio\n",
    "train_size = int(train_ratio * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a37b404b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of indices for the entire dataset\n",
    "indices = list(range(len(full_dataset)))\n",
    "\n",
    "# Randomly shuffle the indices\n",
    "random.shuffle(indices)\n",
    "\n",
    "# Split the indices into training and testing indices\n",
    "train_indices = indices[:train_size]\n",
    "test_indices = indices[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb43a20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training and testing datasets using Subset\n",
    "train_dataset = torch.utils.data.Subset(full_dataset, train_indices)\n",
    "test_dataset = torch.utils.data.Subset(full_dataset, test_indices)\n",
    "\n",
    "# Create DataLoaders for the training and testing datasets\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "37770fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_train_test_data(train_dataloader, test_dataloader):\n",
    "    for images, labels in train_dataloader:\n",
    "        # Move the batch of images and labels to the GPU if available\n",
    "        train_images = images.to(device)\n",
    "        train_labels = labels.to(device)\n",
    "\n",
    "    # Iterate over the testing dataset\n",
    "    for images, labels in test_dataloader:\n",
    "        # Move the batch of images and labels to the GPU if available\n",
    "        test_images = images.to(device)\n",
    "        test_labels = labels.to(device)\n",
    "        \n",
    "    return train_images, train_labels, test_images, test_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "77cc63d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels, test_images, test_labels = give_train_test_data(train_dataloader, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "be278988",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageClassifier, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 32 * 32, 128)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(64, 9)  # Output layer with 9 mushroom classes\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        x = self.pool3(self.relu3(self.conv3(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu4(self.fc1(x))\n",
    "        x = self.relu5(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "74b8a477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 1.9039\n",
      "Epoch 2/50, Loss: 1.6791\n",
      "Epoch 3/50, Loss: 1.4323\n",
      "Epoch 4/50, Loss: 1.0634\n",
      "Epoch 5/50, Loss: 0.5680\n",
      "Epoch 6/50, Loss: 0.2322\n",
      "Epoch 7/50, Loss: 0.1273\n",
      "Epoch 8/50, Loss: 0.0522\n",
      "Epoch 9/50, Loss: 0.0189\n",
      "Epoch 10/50, Loss: 0.0131\n",
      "Epoch 11/50, Loss: 0.0511\n",
      "Epoch 12/50, Loss: 0.1002\n",
      "Epoch 13/50, Loss: 0.0391\n",
      "Epoch 14/50, Loss: 0.0299\n",
      "Epoch 15/50, Loss: 0.0262\n",
      "Epoch 16/50, Loss: 0.0343\n",
      "Epoch 17/50, Loss: 0.0143\n",
      "Epoch 18/50, Loss: 0.0386\n",
      "Epoch 19/50, Loss: 0.0371\n",
      "Epoch 20/50, Loss: 0.0617\n",
      "Epoch 21/50, Loss: 0.0451\n",
      "Epoch 22/50, Loss: 0.0123\n",
      "Epoch 23/50, Loss: 0.0009\n",
      "Epoch 24/50, Loss: 0.0002\n",
      "Epoch 25/50, Loss: 0.0001\n",
      "Epoch 26/50, Loss: 0.0001\n",
      "Epoch 27/50, Loss: 0.0001\n",
      "Epoch 28/50, Loss: 0.0001\n",
      "Epoch 29/50, Loss: 0.0001\n",
      "Epoch 30/50, Loss: 0.0000\n",
      "Epoch 31/50, Loss: 0.0000\n",
      "Epoch 32/50, Loss: 0.0000\n",
      "Epoch 33/50, Loss: 0.0000\n",
      "Epoch 34/50, Loss: 0.0000\n",
      "Epoch 35/50, Loss: 0.0000\n",
      "Epoch 36/50, Loss: 0.0000\n",
      "Epoch 37/50, Loss: 0.0000\n",
      "Epoch 38/50, Loss: 0.0000\n",
      "Epoch 39/50, Loss: 0.0000\n",
      "Epoch 40/50, Loss: 0.0000\n",
      "Epoch 41/50, Loss: 0.0000\n",
      "Epoch 42/50, Loss: 0.0000\n",
      "Epoch 43/50, Loss: 0.0000\n",
      "Epoch 44/50, Loss: 0.0000\n",
      "Epoch 45/50, Loss: 0.0000\n",
      "Epoch 46/50, Loss: 0.0000\n",
      "Epoch 47/50, Loss: 0.0000\n",
      "Epoch 48/50, Loss: 0.0000\n",
      "Epoch 49/50, Loss: 0.0000\n",
      "Epoch 50/50, Loss: 0.0000\n",
      "Testing Accuracy: 0.3969\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Instantiate the ImageClassifier model\n",
    "model = ImageClassifier()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # Iterate over the training dataset\n",
    "    for images, labels in train_dataloader:\n",
    "        # Move the batch of images and labels to the GPU if available\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calculate the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate the loss\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Calculate the average loss for the epoch\n",
    "    average_loss = running_loss / len(train_dataloader)\n",
    "    \n",
    "    # Print the average loss for the epoch\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {average_loss:.4f}\")\n",
    "    \n",
    "# Testing loop\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "\n",
    "# Disable gradient computation\n",
    "with torch.no_grad():\n",
    "    # Iterate over the testing dataset\n",
    "    for images, labels in test_dataloader:\n",
    "        # Move the batch of images and labels to the GPU if available\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Get the predicted labels\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # Update the counts for correct predictions\n",
    "        total_samples += labels.size(0)\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = total_correct / total_samples\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"Testing Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab9c8df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871d115c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a3d746",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
