{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":447652,"sourceType":"datasetVersion","datasetId":203752}],"dockerImageVersionId":25160,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers.core import Activation\nfrom keras.layers.core import Flatten\nfrom keras.layers.core import Dropout\nfrom keras.layers.core import Dense\nfrom keras import backend as K\n\n\nclass SmallerVGGNet:\n    @staticmethod\n    def build(width, height, depth, classes):\n        model = Sequential()\n        inputShape = (height, width, depth)\n        chanDim = -1\n\n        if K.image_data_format() == \"channels_first\":\n            inputShape = (depth, height, width)\n            chanDim = 1\n\n        model.add(Conv2D(32, (3,3), padding=\"same\", input_shape=inputShape))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(axis=chanDim))\n        model.add(MaxPooling2D(pool_size=(3,3)))\n        model.add(Dropout(0.25))\n\n        model.add(Conv2D(64, (3,3), padding=\"same\"))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(axis=chanDim))\n        model.add(Conv2D(64, (3,3), padding=\"same\"))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(axis=chanDim))\n        model.add(MaxPooling2D(pool_size=(2,2)))\n        model.add(Dropout(0.25))\n\n        model.add(Conv2D(128, (3,3), padding=\"same\"))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(axis=chanDim))\n        model.add(Conv2D(128, (3,3), padding=\"same\"))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(axis=chanDim))\n        model.add(MaxPooling2D(pool_size=(2,2)))\n        model.add(Dropout(0.25))\n\n        model.add(Flatten())\n        model.add(Dense(1024))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization())\n        model.add(Dropout(0.5))\n\n        model.add(Dense(classes))\n        model.add(Activation(\"sigmoid\"))\n\n        return model\n","metadata":{"execution":{"iopub.status.busy":"2023-12-27T11:34:42.895831Z","iopub.execute_input":"2023-12-27T11:34:42.896113Z","iopub.status.idle":"2023-12-27T11:34:44.011026Z","shell.execute_reply.started":"2023-12-27T11:34:42.896071Z","shell.execute_reply":"2023-12-27T11:34:44.010339Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"Using TensorFlow backend.\n","output_type":"stream"}]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-27T11:55:19.142753Z","iopub.execute_input":"2023-12-27T11:55:19.143138Z","iopub.status.idle":"2023-12-27T11:55:19.157523Z","shell.execute_reply.started":"2023-12-27T11:55:19.143072Z","shell.execute_reply":"2023-12-27T11:55:19.156731Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"['test_ApKoW4T.csv', 'sample_submission_ns2btKE.csv', 'train']\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib\nmatplotlib.use(\"Agg\")\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import img_to_array\nfrom keras.utils import to_categorical\nfrom keras.utils import plot_model\nfrom sklearn.model_selection import train_test_split\n#from model.smallervggnet import SmallerVGGNet\nfrom keras.callbacks import ModelCheckpoint\nimport keras.backend as K\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport argparse\nimport random\nimport cv2\nimport os\nimport glob\nimport pandas as pd\nimport tensorflow as tf","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2023-12-27T11:34:44.030075Z","iopub.execute_input":"2023-12-27T11:34:44.030307Z","iopub.status.idle":"2023-12-27T11:34:44.740618Z","shell.execute_reply.started":"2023-12-27T11:34:44.030259Z","shell.execute_reply":"2023-12-27T11:34:44.739656Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def category_0_to_n_minus1(x):\n    x = x - 1\n    return x\n\ndef f1(y_true, y_pred):\n    y_pred = K.round(y_pred)\n    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n\n    p = tp / (tp + fp + K.epsilon())\n    r = tp / (tp + fn + K.epsilon())\n\n    f1 = 2*p*r / (p+r+K.epsilon())\n    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n    return K.mean(f1)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T11:34:44.742575Z","iopub.execute_input":"2023-12-27T11:34:44.742885Z","iopub.status.idle":"2023-12-27T11:34:44.751960Z","shell.execute_reply.started":"2023-12-27T11:34:44.742830Z","shell.execute_reply":"2023-12-27T11:34:44.750900Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv(\"../input/train/train.csv\")\ntrain_data.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T11:34:44.753177Z","iopub.execute_input":"2023-12-27T11:34:44.753492Z","iopub.status.idle":"2023-12-27T11:34:44.800526Z","shell.execute_reply.started":"2023-12-27T11:34:44.753431Z","shell.execute_reply":"2023-12-27T11:34:44.799636Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"         image  category\n0  2823080.jpg         1\n1  2870024.jpg         1\n2  2662125.jpg         2\n3  2900420.jpg         3\n4  2804883.jpg         2","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2823080.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2870024.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2662125.jpg</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2900420.jpg</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2804883.jpg</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_data['category'] = train_data['category'].apply(category_0_to_n_minus1)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T11:34:44.802325Z","iopub.execute_input":"2023-12-27T11:34:44.802807Z","iopub.status.idle":"2023-12-27T11:34:44.814948Z","shell.execute_reply.started":"2023-12-27T11:34:44.802753Z","shell.execute_reply":"2023-12-27T11:34:44.813871Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# initial parameters\nepochs = 100\nlr = 1e-3\nbatch_size = 64\nimg_dims = (96,96,3)\n\ndata = []\nlabels = []\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-27T11:34:44.816281Z","iopub.execute_input":"2023-12-27T11:34:44.816661Z","iopub.status.idle":"2023-12-27T11:34:44.830846Z","shell.execute_reply.started":"2023-12-27T11:34:44.816600Z","shell.execute_reply":"2023-12-27T11:34:44.829763Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"random.seed(42)\nrandom.shuffle(train_data.values)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T11:34:44.832379Z","iopub.execute_input":"2023-12-27T11:34:44.832968Z","iopub.status.idle":"2023-12-27T11:34:44.908579Z","shell.execute_reply.started":"2023-12-27T11:34:44.832897Z","shell.execute_reply":"2023-12-27T11:34:44.907621Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# create groud-truth label from the image path\nfor index, row in train_data.iterrows():\n    img_path = '../input/train/images/' + row['image']\n    image = cv2.imread(img_path)\n    \n    image = cv2.resize(image, (img_dims[0],img_dims[1]))\n    image = img_to_array(image)\n    data.append(image)\n\n    label = row['category']\n        \n    labels.append([label])","metadata":{"execution":{"iopub.status.busy":"2023-12-27T11:34:44.910113Z","iopub.execute_input":"2023-12-27T11:34:44.910416Z","iopub.status.idle":"2023-12-27T11:35:52.051165Z","shell.execute_reply.started":"2023-12-27T11:34:44.910354Z","shell.execute_reply":"2023-12-27T11:35:52.050509Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# pre-processing\ndata = np.array(data, dtype=\"float\") / 255.0\nlabels = np.array(labels)\n\n# split dataset for training and validation\n(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.2,\n                                                  random_state=42)\ntrainY = to_categorical(trainY, num_classes=5)\ntestY = to_categorical(testY, num_classes=5)\n\n# augmenting datset \naug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n                         height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n                         horizontal_flip=True, fill_mode=\"nearest\")\n\n# build model\nmodel = SmallerVGGNet.build(width=img_dims[0], height=img_dims[1], depth=img_dims[2],\n                            classes=5)\n\n# compile the model\nopt = Adam(lr=lr, decay=lr/epochs)\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=['accuracy', f1])\ncheckpoint = ModelCheckpoint('ship_detection.model', monitor='val_f1', verbose=1, save_best_only=True, mode='max')\ncallbacks_list = [checkpoint]\n# train the model\nH = model.fit_generator(aug.flow(trainX, trainY, batch_size=batch_size),\n                        validation_data=(testX,testY),\n                        steps_per_epoch=len(trainX) // batch_size,\n                        epochs=epochs, callbacks=callbacks_list, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T11:35:52.052620Z","iopub.execute_input":"2023-12-27T11:35:52.052878Z","iopub.status.idle":"2023-12-27T11:52:28.169742Z","shell.execute_reply.started":"2023-12-27T11:35:52.052827Z","shell.execute_reply":"2023-12-27T11:52:28.168030Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\nWARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\nWARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nEpoch 1/100\n78/78 [==============================] - 13s 167ms/step - loss: 1.4900 - acc: 0.3730 - f1: 0.3980 - val_loss: 1.4667 - val_acc: 0.5244 - val_f1: 0.4951\n\nEpoch 00001: val_f1 improved from -inf to 0.49515, saving model to ship_detection.model\nEpoch 2/100\n78/78 [==============================] - 9s 118ms/step - loss: 1.2089 - acc: 0.5033 - f1: 0.4701 - val_loss: 1.3668 - val_acc: 0.4924 - val_f1: 0.4872\n\nEpoch 00002: val_f1 did not improve from 0.49515\nEpoch 3/100\n78/78 [==============================] - 10s 126ms/step - loss: 1.1470 - acc: 0.5508 - f1: 0.4992 - val_loss: 1.5168 - val_acc: 0.4620 - val_f1: 0.4841\n\nEpoch 00003: val_f1 did not improve from 0.49515\nEpoch 4/100\n78/78 [==============================] - 10s 128ms/step - loss: 1.1166 - acc: 0.5566 - f1: 0.5192 - val_loss: 3.4586 - val_acc: 0.3917 - val_f1: 0.3020\n\nEpoch 00004: val_f1 did not improve from 0.49515\nEpoch 5/100\n78/78 [==============================] - 10s 126ms/step - loss: 1.0774 - acc: 0.5654 - f1: 0.5273 - val_loss: 1.6427 - val_acc: 0.4628 - val_f1: 0.4798\n\nEpoch 00005: val_f1 did not improve from 0.49515\nEpoch 6/100\n78/78 [==============================] - 10s 125ms/step - loss: 1.0267 - acc: 0.5883 - f1: 0.5507 - val_loss: 1.0350 - val_acc: 0.6011 - val_f1: 0.5382\n\nEpoch 00006: val_f1 improved from 0.49515 to 0.53820, saving model to ship_detection.model\nEpoch 7/100\n78/78 [==============================] - 10s 126ms/step - loss: 0.9602 - acc: 0.6049 - f1: 0.5797 - val_loss: 1.4013 - val_acc: 0.4692 - val_f1: 0.5150\n\nEpoch 00007: val_f1 did not improve from 0.53820\nEpoch 8/100\n78/78 [==============================] - 10s 128ms/step - loss: 0.9749 - acc: 0.5889 - f1: 0.5744 - val_loss: 0.9555 - val_acc: 0.5987 - val_f1: 0.6081\n\nEpoch 00008: val_f1 improved from 0.53820 to 0.60806, saving model to ship_detection.model\nEpoch 9/100\n78/78 [==============================] - 10s 124ms/step - loss: 0.8845 - acc: 0.6426 - f1: 0.6105 - val_loss: 1.1582 - val_acc: 0.5212 - val_f1: 0.5346\n\nEpoch 00009: val_f1 did not improve from 0.60806\nEpoch 10/100\n78/78 [==============================] - 10s 126ms/step - loss: 0.8755 - acc: 0.6498 - f1: 0.6239 - val_loss: 0.9433 - val_acc: 0.6307 - val_f1: 0.6177\n\nEpoch 00010: val_f1 improved from 0.60806 to 0.61770, saving model to ship_detection.model\nEpoch 11/100\n78/78 [==============================] - 10s 127ms/step - loss: 0.8249 - acc: 0.6590 - f1: 0.6426 - val_loss: 1.0184 - val_acc: 0.5803 - val_f1: 0.5996\n\nEpoch 00011: val_f1 did not improve from 0.61770\nEpoch 12/100\n78/78 [==============================] - 10s 125ms/step - loss: 0.8038 - acc: 0.6951 - f1: 0.6586 - val_loss: 1.0988 - val_acc: 0.5731 - val_f1: 0.5960\n\nEpoch 00012: val_f1 did not improve from 0.61770\nEpoch 13/100\n78/78 [==============================] - 10s 125ms/step - loss: 0.7388 - acc: 0.7051 - f1: 0.6867 - val_loss: 0.8970 - val_acc: 0.6491 - val_f1: 0.6529\n\nEpoch 00013: val_f1 improved from 0.61770 to 0.65288, saving model to ship_detection.model\nEpoch 14/100\n78/78 [==============================] - 10s 126ms/step - loss: 0.7573 - acc: 0.6924 - f1: 0.6818 - val_loss: 2.0065 - val_acc: 0.4756 - val_f1: 0.5426\n\nEpoch 00014: val_f1 did not improve from 0.65288\nEpoch 15/100\n78/78 [==============================] - 10s 126ms/step - loss: 0.7037 - acc: 0.7203 - f1: 0.7028 - val_loss: 1.8354 - val_acc: 0.4644 - val_f1: 0.4657\n\nEpoch 00015: val_f1 did not improve from 0.65288\nEpoch 16/100\n78/78 [==============================] - 10s 126ms/step - loss: 0.7093 - acc: 0.7273 - f1: 0.7035 - val_loss: 0.7724 - val_acc: 0.6954 - val_f1: 0.6968\n\nEpoch 00016: val_f1 improved from 0.65288 to 0.69675, saving model to ship_detection.model\nEpoch 17/100\n78/78 [==============================] - 10s 126ms/step - loss: 0.6658 - acc: 0.7373 - f1: 0.7209 - val_loss: 0.6616 - val_acc: 0.7402 - val_f1: 0.7508\n\nEpoch 00017: val_f1 improved from 0.69675 to 0.75078, saving model to ship_detection.model\nEpoch 18/100\n78/78 [==============================] - 10s 126ms/step - loss: 0.6306 - acc: 0.7548 - f1: 0.7455 - val_loss: 0.8034 - val_acc: 0.7018 - val_f1: 0.7126\n\nEpoch 00018: val_f1 did not improve from 0.75078\nEpoch 19/100\n78/78 [==============================] - 10s 125ms/step - loss: 0.6165 - acc: 0.7634 - f1: 0.7450 - val_loss: 0.7882 - val_acc: 0.6954 - val_f1: 0.6693\n\nEpoch 00019: val_f1 did not improve from 0.75078\nEpoch 20/100\n78/78 [==============================] - 10s 126ms/step - loss: 0.5979 - acc: 0.7722 - f1: 0.7535 - val_loss: 0.5524 - val_acc: 0.7978 - val_f1: 0.7950\n\nEpoch 00020: val_f1 improved from 0.75078 to 0.79501, saving model to ship_detection.model\nEpoch 21/100\n78/78 [==============================] - 10s 126ms/step - loss: 0.5930 - acc: 0.7768 - f1: 0.7632 - val_loss: 0.7032 - val_acc: 0.7426 - val_f1: 0.7386\n\nEpoch 00021: val_f1 did not improve from 0.79501\nEpoch 22/100\n78/78 [==============================] - 10s 125ms/step - loss: 0.5856 - acc: 0.7778 - f1: 0.7576 - val_loss: 0.5948 - val_acc: 0.7738 - val_f1: 0.7723\n\nEpoch 00022: val_f1 did not improve from 0.79501\nEpoch 23/100\n78/78 [==============================] - 10s 128ms/step - loss: 0.5750 - acc: 0.7804 - f1: 0.7658 - val_loss: 1.2417 - val_acc: 0.5971 - val_f1: 0.5646\n\nEpoch 00023: val_f1 did not improve from 0.79501\nEpoch 24/100\n78/78 [==============================] - 10s 128ms/step - loss: 0.5817 - acc: 0.7794 - f1: 0.7544 - val_loss: 0.6150 - val_acc: 0.7650 - val_f1: 0.7523\n\nEpoch 00024: val_f1 did not improve from 0.79501\nEpoch 25/100\n78/78 [==============================] - 10s 125ms/step - loss: 0.5398 - acc: 0.7944 - f1: 0.7824 - val_loss: 0.8674 - val_acc: 0.6787 - val_f1: 0.6922\n\nEpoch 00025: val_f1 did not improve from 0.79501\nEpoch 26/100\n78/78 [==============================] - 10s 125ms/step - loss: 0.5491 - acc: 0.7868 - f1: 0.7738 - val_loss: 0.7557 - val_acc: 0.7442 - val_f1: 0.7493\n\nEpoch 00026: val_f1 did not improve from 0.79501\nEpoch 27/100\n78/78 [==============================] - 10s 128ms/step - loss: 0.5170 - acc: 0.8022 - f1: 0.7882 - val_loss: 1.1782 - val_acc: 0.6299 - val_f1: 0.6292\n\nEpoch 00027: val_f1 did not improve from 0.79501\nEpoch 28/100\n78/78 [==============================] - 10s 126ms/step - loss: 0.5201 - acc: 0.8067 - f1: 0.7867 - val_loss: 0.6160 - val_acc: 0.7762 - val_f1: 0.7729\n\nEpoch 00028: val_f1 did not improve from 0.79501\nEpoch 29/100\n78/78 [==============================] - 10s 125ms/step - loss: 0.4800 - acc: 0.8151 - f1: 0.8004 - val_loss: 1.0318 - val_acc: 0.6731 - val_f1: 0.6448\n\nEpoch 00029: val_f1 did not improve from 0.79501\nEpoch 30/100\n78/78 [==============================] - 10s 128ms/step - loss: 0.4756 - acc: 0.8147 - f1: 0.7998 - val_loss: 0.6602 - val_acc: 0.7762 - val_f1: 0.7591\n\nEpoch 00030: val_f1 did not improve from 0.79501\nEpoch 31/100\n78/78 [==============================] - 10s 125ms/step - loss: 0.4526 - acc: 0.8295 - f1: 0.8130 - val_loss: 0.5488 - val_acc: 0.8018 - val_f1: 0.7981\n\nEpoch 00031: val_f1 improved from 0.79501 to 0.79806, saving model to ship_detection.model\nEpoch 32/100\n78/78 [==============================] - 10s 126ms/step - loss: 0.4783 - acc: 0.8151 - f1: 0.8047 - val_loss: 0.6619 - val_acc: 0.7834 - val_f1: 0.7676\n\nEpoch 00032: val_f1 did not improve from 0.79806\nEpoch 33/100\n78/78 [==============================] - 10s 127ms/step - loss: 0.5546 - acc: 0.7920 - f1: 0.7784 - val_loss: 1.1359 - val_acc: 0.6451 - val_f1: 0.6289\n\nEpoch 00033: val_f1 did not improve from 0.79806\nEpoch 34/100\n78/78 [==============================] - 10s 125ms/step - loss: 0.5169 - acc: 0.7966 - f1: 0.7794 - val_loss: 0.7482 - val_acc: 0.7426 - val_f1: 0.7430\n\nEpoch 00034: val_f1 did not improve from 0.79806\nEpoch 35/100\n78/78 [==============================] - 10s 125ms/step - loss: 0.4374 - acc: 0.8289 - f1: 0.8139 - val_loss: 0.6360 - val_acc: 0.7722 - val_f1: 0.7765\n\nEpoch 00035: val_f1 did not improve from 0.79806\nEpoch 36/100\n78/78 [==============================] - 10s 127ms/step - loss: 0.4758 - acc: 0.8189 - f1: 0.8069 - val_loss: 0.5333 - val_acc: 0.8010 - val_f1: 0.7895\n\nEpoch 00036: val_f1 did not improve from 0.79806\nEpoch 37/100\n78/78 [==============================] - 10s 125ms/step - loss: 0.4331 - acc: 0.8299 - f1: 0.8172 - val_loss: 0.6948 - val_acc: 0.7810 - val_f1: 0.7584\n\nEpoch 00037: val_f1 did not improve from 0.79806\nEpoch 38/100\n78/78 [==============================] - 10s 125ms/step - loss: 0.4191 - acc: 0.8303 - f1: 0.8208 - val_loss: 0.6311 - val_acc: 0.7890 - val_f1: 0.7859\n\nEpoch 00038: val_f1 did not improve from 0.79806\nEpoch 39/100\n78/78 [==============================] - 10s 126ms/step - loss: 0.4590 - acc: 0.8223 - f1: 0.8066 - val_loss: 0.6923 - val_acc: 0.7706 - val_f1: 0.7567\n\nEpoch 00039: val_f1 did not improve from 0.79806\nEpoch 40/100\n78/78 [==============================] - 10s 128ms/step - loss: 0.4323 - acc: 0.8341 - f1: 0.8205 - val_loss: 0.7246 - val_acc: 0.7690 - val_f1: 0.7365\n\nEpoch 00040: val_f1 did not improve from 0.79806\nEpoch 41/100\n78/78 [==============================] - 10s 128ms/step - loss: 0.4338 - acc: 0.8325 - f1: 0.8153 - val_loss: 0.6969 - val_acc: 0.7794 - val_f1: 0.7540\n\nEpoch 00041: val_f1 did not improve from 0.79806\nEpoch 42/100\n78/78 [==============================] - 10s 127ms/step - loss: 0.4016 - acc: 0.8427 - f1: 0.8191 - val_loss: 1.0483 - val_acc: 0.6978 - val_f1: 0.6379\n\nEpoch 00042: val_f1 did not improve from 0.79806\nEpoch 43/100\n78/78 [==============================] - 10s 128ms/step - loss: 0.4148 - acc: 0.8453 - f1: 0.8239 - val_loss: 0.5901 - val_acc: 0.8010 - val_f1: 0.7990\n\nEpoch 00043: val_f1 improved from 0.79806 to 0.79901, saving model to ship_detection.model\nEpoch 44/100\n78/78 [==============================] - 10s 124ms/step - loss: 0.4163 - acc: 0.8363 - f1: 0.8227 - val_loss: 0.6385 - val_acc: 0.7706 - val_f1: 0.7580\n\nEpoch 00044: val_f1 did not improve from 0.79901\nEpoch 45/100\n78/78 [==============================] - 10s 125ms/step - loss: 0.3948 - acc: 0.8433 - f1: 0.8320 - val_loss: 0.4602 - val_acc: 0.8409 - val_f1: 0.8315\n\nEpoch 00045: val_f1 improved from 0.79901 to 0.83148, saving model to ship_detection.model\nEpoch 46/100\n78/78 [==============================] - 10s 128ms/step - loss: 0.3827 - acc: 0.8489 - f1: 0.8389 - val_loss: 0.5837 - val_acc: 0.7970 - val_f1: 0.7904\n\nEpoch 00046: val_f1 did not improve from 0.83148\nEpoch 47/100\n78/78 [==============================] - 10s 126ms/step - loss: 0.3853 - acc: 0.8487 - f1: 0.8377 - val_loss: 0.5654 - val_acc: 0.8050 - val_f1: 0.7846\n\nEpoch 00047: val_f1 did not improve from 0.83148\nEpoch 48/100\n78/78 [==============================] - 10s 126ms/step - loss: 0.3634 - acc: 0.8569 - f1: 0.8454 - val_loss: 0.6419 - val_acc: 0.7850 - val_f1: 0.7729\n\nEpoch 00048: val_f1 did not improve from 0.83148\nEpoch 49/100\n78/78 [==============================] - 10s 129ms/step - loss: 0.3864 - acc: 0.8483 - f1: 0.8364 - val_loss: 1.1456 - val_acc: 0.6579 - val_f1: 0.6425\n\nEpoch 00049: val_f1 did not improve from 0.83148\nEpoch 50/100\n78/78 [==============================] - 10s 125ms/step - loss: 0.3913 - acc: 0.8511 - f1: 0.8325 - val_loss: 0.7056 - val_acc: 0.7778 - val_f1: 0.7530\n\nEpoch 00050: val_f1 did not improve from 0.83148\nEpoch 51/100\n78/78 [==============================] - 10s 126ms/step - loss: 0.4047 - acc: 0.8449 - f1: 0.8313 - val_loss: 0.6116 - val_acc: 0.7922 - val_f1: 0.7888\n\nEpoch 00051: val_f1 did not improve from 0.83148\nEpoch 52/100\n78/78 [==============================] - 10s 128ms/step - loss: 0.3588 - acc: 0.8593 - f1: 0.8396 - val_loss: 0.5321 - val_acc: 0.8137 - val_f1: 0.8127\n\nEpoch 00052: val_f1 did not improve from 0.83148\nEpoch 53/100\n78/78 [==============================] - 10s 127ms/step - loss: 0.3770 - acc: 0.8565 - f1: 0.8362 - val_loss: 0.4884 - val_acc: 0.8209 - val_f1: 0.8242\n\nEpoch 00053: val_f1 did not improve from 0.83148\nEpoch 54/100\n78/78 [==============================] - 10s 126ms/step - loss: 0.3723 - acc: 0.8597 - f1: 0.8392 - val_loss: 0.5096 - val_acc: 0.8409 - val_f1: 0.8211\n\nEpoch 00054: val_f1 did not improve from 0.83148\nEpoch 55/100\n78/78 [==============================] - 10s 128ms/step - loss: 0.3202 - acc: 0.8744 - f1: 0.8616 - val_loss: 0.4473 - val_acc: 0.8609 - val_f1: 0.8412\n\nEpoch 00055: val_f1 improved from 0.83148 to 0.84120, saving model to ship_detection.model\nEpoch 56/100\n78/78 [==============================] - 10s 126ms/step - loss: 0.3349 - acc: 0.8688 - f1: 0.8454 - val_loss: 0.5485 - val_acc: 0.8233 - val_f1: 0.8102\n\nEpoch 00056: val_f1 did not improve from 0.84120\nEpoch 57/100\n78/78 [==============================] - 10s 125ms/step - loss: 0.3371 - acc: 0.8695 - f1: 0.8537 - val_loss: 0.7074 - val_acc: 0.7962 - val_f1: 0.7691\n\nEpoch 00057: val_f1 did not improve from 0.84120\nEpoch 58/100\n78/78 [==============================] - 10s 125ms/step - loss: 0.3250 - acc: 0.8746 - f1: 0.8571 - val_loss: 0.7236 - val_acc: 0.7714 - val_f1: 0.7720\n\nEpoch 00058: val_f1 did not improve from 0.84120\nEpoch 59/100\n78/78 [==============================] - 10s 126ms/step - loss: 0.3050 - acc: 0.8822 - f1: 0.8670 - val_loss: 0.7763 - val_acc: 0.7698 - val_f1: 0.7523\n\nEpoch 00059: val_f1 did not improve from 0.84120\nEpoch 60/100\n78/78 [==============================] - 10s 125ms/step - loss: 0.3526 - acc: 0.8650 - f1: 0.8478 - val_loss: 1.0005 - val_acc: 0.7226 - val_f1: 0.7086\n\nEpoch 00060: val_f1 did not improve from 0.84120\nEpoch 61/100\n78/78 [==============================] - 10s 126ms/step - loss: 0.3198 - acc: 0.8748 - f1: 0.8614 - val_loss: 0.7663 - val_acc: 0.7754 - val_f1: 0.7684\n\nEpoch 00061: val_f1 did not improve from 0.84120\nEpoch 62/100\n78/78 [==============================] - 10s 126ms/step - loss: 0.2984 - acc: 0.8820 - f1: 0.8645 - val_loss: 0.5044 - val_acc: 0.8153 - val_f1: 0.8145\n\nEpoch 00062: val_f1 did not improve from 0.84120\nEpoch 63/100\n78/78 [==============================] - 10s 125ms/step - loss: 0.3186 - acc: 0.8806 - f1: 0.8539 - val_loss: 0.6080 - val_acc: 0.8082 - val_f1: 0.7787\n\nEpoch 00063: val_f1 did not improve from 0.84120\nEpoch 64/100\n78/78 [==============================] - 10s 125ms/step - loss: 0.3145 - acc: 0.8804 - f1: 0.8532 - val_loss: 0.4232 - val_acc: 0.8537 - val_f1: 0.8511\n\nEpoch 00064: val_f1 improved from 0.84120 to 0.85109, saving model to ship_detection.model\nEpoch 65/100\n78/78 [==============================] - 10s 127ms/step - loss: 0.2773 - acc: 0.8898 - f1: 0.8703 - val_loss: 0.6119 - val_acc: 0.8018 - val_f1: 0.7736\n\nEpoch 00065: val_f1 did not improve from 0.85109\nEpoch 66/100\n78/78 [==============================] - 10s 125ms/step - loss: 0.2677 - acc: 0.8974 - f1: 0.8708 - val_loss: 0.6009 - val_acc: 0.8074 - val_f1: 0.7847\n\nEpoch 00066: val_f1 did not improve from 0.85109\nEpoch 67/100\n78/78 [==============================] - 10s 126ms/step - loss: 0.2919 - acc: 0.8866 - f1: 0.8628 - val_loss: 1.3980 - val_acc: 0.6539 - val_f1: 0.6098\n\nEpoch 00067: val_f1 did not improve from 0.85109\nEpoch 68/100\n78/78 [==============================] - 10s 128ms/step - loss: 0.3889 - acc: 0.8527 - f1: 0.8304 - val_loss: 1.0804 - val_acc: 0.6962 - val_f1: 0.6628\n\nEpoch 00068: val_f1 did not improve from 0.85109\nEpoch 69/100\n78/78 [==============================] - 10s 124ms/step - loss: 0.3746 - acc: 0.8608 - f1: 0.8363 - val_loss: 1.1175 - val_acc: 0.6986 - val_f1: 0.6999\n\nEpoch 00069: val_f1 did not improve from 0.85109\nEpoch 70/100\n78/78 [==============================] - 10s 125ms/step - loss: 0.3233 - acc: 0.8740 - f1: 0.8521 - val_loss: 0.9645 - val_acc: 0.7018 - val_f1: 0.6342\n\nEpoch 00070: val_f1 did not improve from 0.85109\nEpoch 71/100\n78/78 [==============================] - 10s 130ms/step - loss: 0.3361 - acc: 0.8645 - f1: 0.8465 - val_loss: 0.9504 - val_acc: 0.7026 - val_f1: 0.7089\n\nEpoch 00071: val_f1 did not improve from 0.85109\nEpoch 72/100\n78/78 [==============================] - 10s 126ms/step - loss: 0.2942 - acc: 0.8842 - f1: 0.8623 - val_loss: 0.6028 - val_acc: 0.8034 - val_f1: 0.7899\n\nEpoch 00072: val_f1 did not improve from 0.85109\nEpoch 73/100\n78/78 [==============================] - 10s 126ms/step - loss: 0.2794 - acc: 0.8890 - f1: 0.8597 - val_loss: 0.5653 - val_acc: 0.8249 - val_f1: 0.8092\n\nEpoch 00073: val_f1 did not improve from 0.85109\nEpoch 74/100\n78/78 [==============================] - 10s 125ms/step - loss: 0.2962 - acc: 0.8828 - f1: 0.8634 - val_loss: 0.4706 - val_acc: 0.8497 - val_f1: 0.8338\n\nEpoch 00074: val_f1 did not improve from 0.85109\nEpoch 75/100\n78/78 [==============================] - 10s 127ms/step - loss: 0.2557 - acc: 0.9032 - f1: 0.8812 - val_loss: 0.5406 - val_acc: 0.8313 - val_f1: 0.8189\n\nEpoch 00075: val_f1 did not improve from 0.85109\nEpoch 76/100\n78/78 [==============================] - 10s 126ms/step - loss: 0.2569 - acc: 0.9032 - f1: 0.8780 - val_loss: 0.5843 - val_acc: 0.8313 - val_f1: 0.8032\n\nEpoch 00076: val_f1 did not improve from 0.85109\nEpoch 77/100\n78/78 [==============================] - 10s 125ms/step - loss: 0.2452 - acc: 0.9022 - f1: 0.8796 - val_loss: 0.4841 - val_acc: 0.8513 - val_f1: 0.8321\n\nEpoch 00077: val_f1 did not improve from 0.85109\nEpoch 78/100\n78/78 [==============================] - 10s 126ms/step - loss: 0.2446 - acc: 0.9046 - f1: 0.8697 - val_loss: 0.5347 - val_acc: 0.8393 - val_f1: 0.8221\n\nEpoch 00078: val_f1 did not improve from 0.85109\nEpoch 79/100\n78/78 [==============================] - 10s 127ms/step - loss: 0.2593 - acc: 0.8986 - f1: 0.8670 - val_loss: 0.6745 - val_acc: 0.8225 - val_f1: 0.6250\n\nEpoch 00079: val_f1 did not improve from 0.85109\nEpoch 80/100\n78/78 [==============================] - 10s 126ms/step - loss: 0.2354 - acc: 0.9137 - f1: 0.8831 - val_loss: 0.7052 - val_acc: 0.8058 - val_f1: 0.7826\n\nEpoch 00080: val_f1 did not improve from 0.85109\nEpoch 81/100\n78/78 [==============================] - 10s 128ms/step - loss: 0.2510 - acc: 0.9050 - f1: 0.8740 - val_loss: 0.4386 - val_acc: 0.8721 - val_f1: 0.8388\n\nEpoch 00081: val_f1 did not improve from 0.85109\nEpoch 82/100\n78/78 [==============================] - 10s 124ms/step - loss: 0.2271 - acc: 0.9152 - f1: 0.8863 - val_loss: 0.5639 - val_acc: 0.8257 - val_f1: 0.8111\n\nEpoch 00082: val_f1 did not improve from 0.85109\nEpoch 83/100\n78/78 [==============================] - 10s 127ms/step - loss: 0.2695 - acc: 0.9026 - f1: 0.8682 - val_loss: 0.5450 - val_acc: 0.8289 - val_f1: 0.8083\n\nEpoch 00083: val_f1 did not improve from 0.85109\nEpoch 84/100\n78/78 [==============================] - 10s 125ms/step - loss: 0.2315 - acc: 0.9080 - f1: 0.8816 - val_loss: 0.5960 - val_acc: 0.8257 - val_f1: 0.7987\n\nEpoch 00084: val_f1 did not improve from 0.85109\nEpoch 85/100\n78/78 [==============================] - 10s 125ms/step - loss: 0.2403 - acc: 0.9104 - f1: 0.8798 - val_loss: 0.8418 - val_acc: 0.7738 - val_f1: 0.7481\n\nEpoch 00085: val_f1 did not improve from 0.85109\nEpoch 86/100\n78/78 [==============================] - 10s 126ms/step - loss: 0.2993 - acc: 0.8854 - f1: 0.8544 - val_loss: 0.7916 - val_acc: 0.7834 - val_f1: 0.7755\n\nEpoch 00086: val_f1 did not improve from 0.85109\nEpoch 87/100\n78/78 [==============================] - 10s 127ms/step - loss: 0.2661 - acc: 0.8924 - f1: 0.8749 - val_loss: 0.4879 - val_acc: 0.8457 - val_f1: 0.8296\n\nEpoch 00087: val_f1 did not improve from 0.85109\nEpoch 88/100\n78/78 [==============================] - 10s 126ms/step - loss: 0.2233 - acc: 0.9183 - f1: 0.8840 - val_loss: 0.5510 - val_acc: 0.8433 - val_f1: 0.8143\n\nEpoch 00088: val_f1 did not improve from 0.85109\nEpoch 89/100\n78/78 [==============================] - 10s 126ms/step - loss: 0.2341 - acc: 0.9130 - f1: 0.8795 - val_loss: 0.7159 - val_acc: 0.8074 - val_f1: 0.7807\n\nEpoch 00089: val_f1 did not improve from 0.85109\nEpoch 90/100\n78/78 [==============================] - 10s 126ms/step - loss: 0.1985 - acc: 0.9237 - f1: 0.8858 - val_loss: 0.7146 - val_acc: 0.7994 - val_f1: 0.7729\n\nEpoch 00090: val_f1 did not improve from 0.85109\nEpoch 91/100\n78/78 [==============================] - 10s 126ms/step - loss: 0.2105 - acc: 0.9159 - f1: 0.8849 - val_loss: 0.5119 - val_acc: 0.8601 - val_f1: 0.8408\n\nEpoch 00091: val_f1 did not improve from 0.85109\nEpoch 92/100\n78/78 [==============================] - 10s 124ms/step - loss: 0.2139 - acc: 0.9189 - f1: 0.8786 - val_loss: 0.6493 - val_acc: 0.8321 - val_f1: 0.7944\n\nEpoch 00092: val_f1 did not improve from 0.85109\nEpoch 93/100\n78/78 [==============================] - 10s 126ms/step - loss: 0.2210 - acc: 0.9168 - f1: 0.8814 - val_loss: 0.4234 - val_acc: 0.8665 - val_f1: 0.8439\n\nEpoch 00093: val_f1 did not improve from 0.85109\nEpoch 94/100\n78/78 [==============================] - 10s 126ms/step - loss: 0.2382 - acc: 0.9096 - f1: 0.8708 - val_loss: 0.4634 - val_acc: 0.8609 - val_f1: 0.8387\n\nEpoch 00094: val_f1 did not improve from 0.85109\nEpoch 95/100\n78/78 [==============================] - 10s 126ms/step - loss: 0.2398 - acc: 0.9070 - f1: 0.8747 - val_loss: 0.6366 - val_acc: 0.8145 - val_f1: 0.7970\n\nEpoch 00095: val_f1 did not improve from 0.85109\nEpoch 96/100\n78/78 [==============================] - 10s 126ms/step - loss: 0.2047 - acc: 0.9233 - f1: 0.8830 - val_loss: 0.4770 - val_acc: 0.8497 - val_f1: 0.8130\n\nEpoch 00096: val_f1 did not improve from 0.85109\nEpoch 97/100\n78/78 [==============================] - 10s 126ms/step - loss: 0.2181 - acc: 0.9187 - f1: 0.8815 - val_loss: 0.5523 - val_acc: 0.8441 - val_f1: 0.8106\n\nEpoch 00097: val_f1 did not improve from 0.85109\nEpoch 98/100\n78/78 [==============================] - 10s 125ms/step - loss: 0.2065 - acc: 0.9263 - f1: 0.8869 - val_loss: 0.5912 - val_acc: 0.8441 - val_f1: 0.8125\n\nEpoch 00098: val_f1 did not improve from 0.85109\nEpoch 99/100\n78/78 [==============================] - 10s 126ms/step - loss: 0.2129 - acc: 0.9148 - f1: 0.8901 - val_loss: 0.4420 - val_acc: 0.8721 - val_f1: 0.8492\n\nEpoch 00099: val_f1 did not improve from 0.85109\nEpoch 100/100\n78/78 [==============================] - 10s 126ms/step - loss: 0.2147 - acc: 0.9154 - f1: 0.8911 - val_loss: 0.4154 - val_acc: 0.8769 - val_f1: 0.8359\n\nEpoch 00100: val_f1 did not improve from 0.85109\n","output_type":"stream"}]}]}